{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### MNISTサンプル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import caffe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パスを設定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "Creating lmdb...\n",
      "libdc1394 error: Failed to initialize libdc1394\n",
      "I0817 23:45:39.200397   290 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb\n",
      "I0817 23:45:39.200837   290 convert_mnist_data.cpp:88] A total of 60000 items.\n",
      "I0817 23:45:39.200861   290 convert_mnist_data.cpp:89] Rows: 28 Cols: 28\n",
      "I0817 23:45:40.595028   290 convert_mnist_data.cpp:108] Processed 60000 files.\n",
      "libdc1394 error: Failed to initialize libdc1394\n",
      "I0817 23:45:40.646076   291 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb\n",
      "I0817 23:45:40.646564   291 convert_mnist_data.cpp:88] A total of 10000 items.\n",
      "I0817 23:45:40.646591   291 convert_mnist_data.cpp:89] Rows: 28 Cols: 28\n",
      "I0817 23:45:40.872876   291 convert_mnist_data.cpp:108] Processed 10000 files.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "caffe_root = '/opt/caffe'\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "os.chdir(caffe_root)\n",
    "!data/mnist/get_mnist.sh\n",
    "!examples/mnist/create_mnist.sh\n",
    "os.chdir('examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3520\r\n",
      "-rw-r--r-- 1 root root    4520 Aug 17 05:23 convert_mnist_data.cpp\r\n",
      "-rwxr-xr-x 1 root root     634 Aug 17 05:23 create_mnist.sh\r\n",
      "-rw-r--r-- 1 root root    1738 Aug 17 05:23 lenet.prototxt\r\n",
      "-rw-r--r-- 1 root root     777 Aug 17 05:23 lenet_adadelta_solver.prototxt\r\n",
      "-rw-r--r-- 1 root root     778 Aug 17 05:23 lenet_auto_solver.prototxt\r\n",
      "-rw-r--r-- 1 root root    1407 Aug 17 09:14 lenet_auto_test.prototxt\r\n",
      "-rw-r--r-- 1 root root    1407 Aug 17 09:14 lenet_auto_train.prototxt\r\n",
      "-rw-r--r-- 1 root root    6003 Aug 17 05:23 lenet_consolidated_solver.prototxt\r\n",
      "-rw-r--r-- 1 root root 1724885 Aug 17 09:27 lenet_iter_5000.caffemodel\r\n",
      "-rw-r--r-- 1 root root 1724461 Aug 17 09:27 lenet_iter_5000.solverstate\r\n",
      "-rw-r--r-- 1 root root     871 Aug 17 05:23 lenet_multistep_solver.prototxt\r\n",
      "-rw-r--r-- 1 root root     790 Aug 17 05:23 lenet_solver.prototxt\r\n",
      "-rw-r--r-- 1 root root     886 Aug 17 05:23 lenet_solver_adam.prototxt\r\n",
      "-rw-r--r-- 1 root root     830 Aug 17 05:23 lenet_solver_rmsprop.prototxt\r\n",
      "-rw-r--r-- 1 root root    2282 Aug 17 05:23 lenet_train_test.prototxt\r\n",
      "-rw-r--r-- 1 root root    4814 Aug 17 05:23 mnist_autoencoder.prototxt\r\n",
      "-rw-r--r-- 1 root root     433 Aug 17 05:23 mnist_autoencoder_solver.prototxt\r\n",
      "-rw-r--r-- 1 root root     451 Aug 17 05:23 mnist_autoencoder_solver_adadelta.prototxt\r\n",
      "-rw-r--r-- 1 root root     423 Aug 17 05:23 mnist_autoencoder_solver_adagrad.prototxt\r\n",
      "-rw-r--r-- 1 root root     466 Aug 17 05:23 mnist_autoencoder_solver_nesterov.prototxt\r\n",
      "drwxr--r-- 2 root root    4096 Aug 17 09:56 mnist_test_lmdb\r\n",
      "drwxr--r-- 2 root root    4096 Aug 17 09:56 mnist_train_lmdb\r\n",
      "-rw-r--r-- 1 root root   11948 Aug 17 05:23 readme.md\r\n",
      "-rwxr-xr-x 1 root root     101 Aug 17 05:23 train_lenet.sh\r\n",
      "-rwxr-xr-x 1 root root     106 Aug 17 05:23 train_lenet_adam.sh\r\n",
      "-rwxr-xr-x 1 root root     118 Aug 17 05:23 train_lenet_consolidated.sh\r\n",
      "-rwxr-xr-x 1 root root    4518 Aug 17 05:23 train_lenet_docker.sh\r\n",
      "-rwxr-xr-x 1 root root     115 Aug 17 05:23 train_lenet_rmsprop.sh\r\n",
      "-rwxr-xr-x 1 root root     117 Aug 17 05:23 train_mnist_autoencoder.sh\r\n",
      "-rwxr-xr-x 1 root root     120 Aug 17 05:23 train_mnist_autoencoder_adadelta.sh\r\n",
      "-rwxr-xr-x 1 root root     119 Aug 17 05:23 train_mnist_autoencoder_adagrad.sh\r\n",
      "-rwxr-xr-x 1 root root     120 Aug 17 05:23 train_mnist_autoencoder_nesterov.sh\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_net_path = 'mnist/custom_auto_train.prototxt'\n",
    "test_net_path = 'mnist/custom_auto_test.prototxt'\n",
    "solver_config_path = 'mnist/custom_auto_solver.prototxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caffe.set_mode_cpu()\n",
    "solver = None\n",
    "solver = caffe.SGDSolver('mnist/lenet_auto_solver.prototxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### define net\n",
    "def custom_net(lmdb, batch_size):\n",
    "    # define your own net!\n",
    "    n = caffe.NetSpec()\n",
    "    \n",
    "    # keep this data layer for all networks\n",
    "    n.data, n.label = L.Data(batch_size=batch_size, backend=P.Data.LMDB, source=lmdb,\n",
    "                             transform_param=dict(scale=1./255), ntop=2)\n",
    "    \n",
    "    # EDIT HERE to try different networks\n",
    "    # this single layer defines a simple linear classifier\n",
    "    # (in particular this defines a multiway logistic regression)\n",
    "    n.score =   L.InnerProduct(n.data, num_output=10, weight_filler=dict(type='xavier'))\n",
    "    \n",
    "    # EDIT HERE this is the LeNet variant we have already tried\n",
    "    # n.conv1 = L.Convolution(n.data, kernel_size=5, num_output=20, weight_filler=dict(type='xavier'))\n",
    "    # n.pool1 = L.Pooling(n.conv1, kernel_size=2, stride=2, pool=P.Pooling.MAX)\n",
    "    # n.conv2 = L.Convolution(n.pool1, kernel_size=5, num_output=50, weight_filler=dict(type='xavier'))\n",
    "    # n.pool2 = L.Pooling(n.conv2, kernel_size=2, stride=2, pool=P.Pooling.MAX)\n",
    "    # n.fc1 =   L.InnerProduct(n.pool2, num_output=500, weight_filler=dict(type='xavier'))\n",
    "    # EDIT HERE consider L.ELU or L.Sigmoid for the nonlinearity\n",
    "    # n.relu1 = L.ReLU(n.fc1, in_place=True)\n",
    "    # n.score =   L.InnerProduct(n.fc1, num_output=10, weight_filler=dict(type='xavier'))\n",
    "    \n",
    "    # keep this loss layer for all networks\n",
    "    n.loss =  L.SoftmaxWithLoss(n.score, n.label)\n",
    "    \n",
    "    return n.to_proto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from caffe import layers as L, params as P\n",
    "with open(train_net_path, 'w') as f:\n",
    "    f.write(str(custom_net('mnist/mnist_train_lmdb', 64)))    \n",
    "with open(test_net_path, 'w') as f:\n",
    "    f.write(str(custom_net('mnist/mnist_test_lmdb', 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### define solver\n",
    "from pylab import *\n",
    "from caffe.proto import caffe_pb2\n",
    "s = caffe_pb2.SolverParameter()\n",
    "\n",
    "# Set a seed for reproducible experiments:\n",
    "# this controls for randomization in training.\n",
    "s.random_seed = 0xCAFFE\n",
    "\n",
    "# Specify locations of the train and (maybe) test networks.\n",
    "s.train_net = train_net_path\n",
    "s.test_net.append(test_net_path)\n",
    "s.test_interval = 500  # Test after every 500 training iterations.\n",
    "s.test_iter.append(100) # Test on 100 batches each time we test.\n",
    "\n",
    "s.max_iter = 10000     # no. of times to update the net (training iterations)\n",
    " \n",
    "# EDIT HERE to try different solvers\n",
    "# solver types include \"SGD\", \"Adam\", and \"Nesterov\" among others.\n",
    "s.type = \"SGD\"\n",
    "\n",
    "# Set the initial learning rate for SGD.\n",
    "s.base_lr = 0.01  # EDIT HERE to try different learning rates\n",
    "# Set momentum to accelerate learning by\n",
    "# taking weighted average of current and previous updates.\n",
    "s.momentum = 0.9\n",
    "# Set weight decay to regularize and prevent overfitting\n",
    "s.weight_decay = 5e-4\n",
    "\n",
    "# Set `lr_policy` to define how the learning rate changes during training.\n",
    "# This is the same policy as our default LeNet.\n",
    "s.lr_policy = 'inv'\n",
    "s.gamma = 0.0001\n",
    "s.power = 0.75\n",
    "# EDIT HERE to try the fixed rate (and compare with adaptive solvers)\n",
    "# `fixed` is the simplest policy that keeps the learning rate constant.\n",
    "# s.lr_policy = 'fixed'\n",
    "\n",
    "# Display the current training loss and accuracy every 1000 iterations.\n",
    "s.display = 1000\n",
    "\n",
    "# Snapshots are files used to store networks we've trained.\n",
    "# We'll snapshot every 5K iterations -- twice during training.\n",
    "s.snapshot = 5000\n",
    "s.snapshot_prefix = 'mnist/custom_net'\n",
    "\n",
    "# Train on the GPU\n",
    "s.solver_mode = caffe_pb2.SolverParameter.CPU\n",
    "\n",
    "# Write the solver to a temporary file and return its filename.\n",
    "with open(solver_config_path, 'w') as f:\n",
    "    f.write(str(s))\n",
    "\n",
    "### load the solver and create train and test nets\n",
    "solver = None  # ignore this workaround for lmdb data (can't instantiate two solvers on the same data)\n",
    "solver = caffe.get_solver(solver_config_path)\n",
    "solver.solve()\n",
    "### solve\n",
    "#niter = 250  # EDIT HERE increase to train for longer\n",
    "#test_interval = niter / 10\n",
    "# losses will also be stored in the log\n",
    "#train_loss = zeros(niter)\n",
    "#test_acc = zeros(int(np.ceil(niter / test_interval)))\n",
    "\n",
    "# the main solver loop\n",
    "#for it in range(niter):\n",
    "#    solver.step(1)  # SGD by Caffe\n",
    "    \n",
    "    # store the train loss\n",
    "#    train_loss[it] = solver.net.blobs['loss'].data\n",
    "    \n",
    "    # run a full test every so often\n",
    "    # (Caffe can also do this for us and write to a log, but we show here\n",
    "    #  how to do it directly in Python, where more complicated things are easier.)\n",
    "#    if it % test_interval == 0:\n",
    "#        print 'Iteration', it, 'testing...'\n",
    "#        correct = 0\n",
    "#        for test_it in range(100):\n",
    "#            solver.test_nets[0].forward()\n",
    "#            correct += sum(solver.test_nets[0].blobs['score'].data.argmax(1)\n",
    "#                           == solver.test_nets[0].blobs['label'].data)\n",
    "#        test_acc[it // test_interval] = correct / 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3660\r\n",
      "-rw-r--r-- 1 root root    4520 Aug 17 05:23 convert_mnist_data.cpp\r\n",
      "-rwxr-xr-x 1 root root     634 Aug 17 05:23 create_mnist.sh\r\n",
      "-rw-r--r-- 1 root root     346 Aug 17 10:04 custom_auto_solver.prototxt\r\n",
      "-rw-r--r-- 1 root root     490 Aug 17 09:58 custom_auto_test.prototxt\r\n",
      "-rw-r--r-- 1 root root     490 Aug 17 09:58 custom_auto_train.prototxt\r\n",
      "-rw-r--r-- 1 root root   31604 Aug 17 10:04 custom_net_iter_10000.caffemodel\r\n",
      "-rw-r--r-- 1 root root   31469 Aug 17 10:04 custom_net_iter_10000.solverstate\r\n",
      "-rw-r--r-- 1 root root   31604 Aug 17 10:04 custom_net_iter_5000.caffemodel\r\n",
      "-rw-r--r-- 1 root root   31468 Aug 17 10:04 custom_net_iter_5000.solverstate\r\n",
      "-rw-r--r-- 1 root root    1738 Aug 17 05:23 lenet.prototxt\r\n",
      "-rw-r--r-- 1 root root     777 Aug 17 05:23 lenet_adadelta_solver.prototxt\r\n",
      "-rw-r--r-- 1 root root     778 Aug 17 05:23 lenet_auto_solver.prototxt\r\n",
      "-rw-r--r-- 1 root root    1407 Aug 17 09:14 lenet_auto_test.prototxt\r\n",
      "-rw-r--r-- 1 root root    1407 Aug 17 09:14 lenet_auto_train.prototxt\r\n",
      "-rw-r--r-- 1 root root    6003 Aug 17 05:23 lenet_consolidated_solver.prototxt\r\n",
      "-rw-r--r-- 1 root root 1724885 Aug 17 09:27 lenet_iter_5000.caffemodel\r\n",
      "-rw-r--r-- 1 root root 1724461 Aug 17 09:27 lenet_iter_5000.solverstate\r\n",
      "-rw-r--r-- 1 root root     871 Aug 17 05:23 lenet_multistep_solver.prototxt\r\n",
      "-rw-r--r-- 1 root root     790 Aug 17 05:23 lenet_solver.prototxt\r\n",
      "-rw-r--r-- 1 root root     886 Aug 17 05:23 lenet_solver_adam.prototxt\r\n",
      "-rw-r--r-- 1 root root     830 Aug 17 05:23 lenet_solver_rmsprop.prototxt\r\n",
      "-rw-r--r-- 1 root root    2282 Aug 17 05:23 lenet_train_test.prototxt\r\n",
      "-rw-r--r-- 1 root root    4814 Aug 17 05:23 mnist_autoencoder.prototxt\r\n",
      "-rw-r--r-- 1 root root     433 Aug 17 05:23 mnist_autoencoder_solver.prototxt\r\n",
      "-rw-r--r-- 1 root root     451 Aug 17 05:23 mnist_autoencoder_solver_adadelta.prototxt\r\n",
      "-rw-r--r-- 1 root root     423 Aug 17 05:23 mnist_autoencoder_solver_adagrad.prototxt\r\n",
      "-rw-r--r-- 1 root root     466 Aug 17 05:23 mnist_autoencoder_solver_nesterov.prototxt\r\n",
      "drwxr--r-- 2 root root    4096 Aug 17 09:56 mnist_test_lmdb\r\n",
      "drwxr--r-- 2 root root    4096 Aug 17 09:56 mnist_train_lmdb\r\n",
      "-rw-r--r-- 1 root root   11948 Aug 17 05:23 readme.md\r\n",
      "-rwxr-xr-x 1 root root     101 Aug 17 05:23 train_lenet.sh\r\n",
      "-rwxr-xr-x 1 root root     106 Aug 17 05:23 train_lenet_adam.sh\r\n",
      "-rwxr-xr-x 1 root root     118 Aug 17 05:23 train_lenet_consolidated.sh\r\n",
      "-rwxr-xr-x 1 root root    4518 Aug 17 05:23 train_lenet_docker.sh\r\n",
      "-rwxr-xr-x 1 root root     115 Aug 17 05:23 train_lenet_rmsprop.sh\r\n",
      "-rwxr-xr-x 1 root root     117 Aug 17 05:23 train_mnist_autoencoder.sh\r\n",
      "-rwxr-xr-x 1 root root     120 Aug 17 05:23 train_mnist_autoencoder_adadelta.sh\r\n",
      "-rwxr-xr-x 1 root root     119 Aug 17 05:23 train_mnist_autoencoder_adagrad.sh\r\n",
      "-rwxr-xr-x 1 root root     120 Aug 17 05:23 train_mnist_autoencoder_nesterov.sh\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_net: \"mnist/custom_auto_train.prototxt\"\r\n",
      "test_net: \"mnist/custom_auto_test.prototxt\"\r\n",
      "test_iter: 100\r\n",
      "test_interval: 500\r\n",
      "base_lr: 0.01\r\n",
      "display: 1000\r\n",
      "max_iter: 10000\r\n",
      "lr_policy: \"inv\"\r\n",
      "gamma: 0.0001\r\n",
      "power: 0.75\r\n",
      "momentum: 0.9\r\n",
      "weight_decay: 0.0005\r\n",
      "snapshot: 5000\r\n",
      "snapshot_prefix: \"mnist/custom_net\"\r\n",
      "solver_mode: CPU\r\n",
      "random_seed: 831486\r\n",
      "type: \"SGD\"\r\n"
     ]
    }
   ],
   "source": [
    "! cat mnist/custom_auto_solver.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
